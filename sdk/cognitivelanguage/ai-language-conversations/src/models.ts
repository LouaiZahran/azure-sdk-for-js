// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.

export interface AnalyzeConversationTaskBase {
  kind: "AnalyzeConversationTask" | "Conversation";
}

export interface ErrorModel extends Record<string, unknown> {
  /** One of a server-defined set of error codes. */
  code:
    | "InvalidRequest"
    | "InvalidArgument"
    | "Unauthorized"
    | "Forbidden"
    | "NotFound"
    | "ProjectNotFound"
    | "OperationNotFound"
    | "AzureCognitiveSearchNotFound"
    | "AzureCognitiveSearchIndexNotFound"
    | "TooManyRequests"
    | "AzureCognitiveSearchThrottling"
    | "AzureCognitiveSearchIndexLimitReached"
    | "InternalServerError"
    | "ServiceUnavailable"
    | "Timeout"
    | "QuotaExceeded"
    | "Conflict"
    | "Warning";
  /** A human-readable representation of the error. */
  message: string;
  /** The target of the error. */
  target?: string;
  /** An array of details about specific errors that led to this reported error. */
  details?: Array<ErrorModel>;
  /** An object containing more specific information than the current object about the error. */
  innererror?: InnerErrorModel;
}

export interface InnerErrorModel {
  /** One of a server-defined set of error codes. */
  code:
    | "InvalidRequest"
    | "InvalidParameterValue"
    | "KnowledgeBaseNotFound"
    | "AzureCognitiveSearchNotFound"
    | "AzureCognitiveSearchThrottling"
    | "ExtractionFailure"
    | "InvalidRequestBodyFormat"
    | "EmptyRequest"
    | "MissingInputDocuments"
    | "InvalidDocument"
    | "ModelVersionIncorrect"
    | "InvalidDocumentBatch"
    | "UnsupportedLanguageCode"
    | "InvalidCountryHint";
  /** Error message. */
  message: string;
  /** Error details. */
  details?: Record<string, string>;
  /** Error target. */
  target?: string;
  /** An object containing more specific information than the current object about the error. */
  innererror?: InnerErrorModel;
}

export interface AnalyzeConversationJobsInput {
  /** Optional display name for the analysis job. */
  displayName?: string;
  analysisInput: MultiLanguageConversationAnalysisInput;
  /** The set of tasks to execute on the input conversation. */
  tasks: Array<AnalyzeConversationLROTask>;
}

export interface MultiLanguageConversationAnalysisInput {
  conversations: Array<Conversation>;
}

export interface ConversationBase {
  /** Unique identifier for the conversation. */
  id: string;
  /** The language of the conversation item in BCP-47 format. */
  language: string;
  /** Enumeration of supported conversational domains. */
  domain?: "finance" | "healthcare" | "generic";
  modality: "Conversation" | "text" | "transcript";
}

export interface AnalyzeConversationLROTaskBase extends TaskIdentifier {
  kind:
    | "AnalyzeConversationLROTask"
    | "ConversationalPIITask"
    | "ConversationalSummarizationTask";
}

export interface TaskIdentifier {
  taskName?: string;
}

export interface AnalyzeConversationJobResultBase
  extends TaskStateAutoGenerated,
    TaskIdentifier {
  kind:
    | "AnalyzeConversationJobResult"
    | "ConversationalPIIResults"
    | "ConversationalSummarizationResults";
}

export interface TaskStateAutoGenerated {
  /** The last updated time in UTC for the task. */
  lastUpdateDateTime: Date | string;
  /** The status of the task at the mentioned last update time. */
  status:
    | "notStarted"
    | "running"
    | "succeeded"
    | "failed"
    | "cancelled"
    | "cancelling";
}

export interface ConversationRequestStatistics extends RequestStatistics {
  /** Number of conversations submitted in the request. */
  conversationsCount: number;
  /** Number of conversations documents. This excludes empty, over-size limit or non-supported languages documents. */
  validConversationsCount: number;
  /** Number of invalid documents. This includes empty, over-size limit or non-supported languages documents. */
  erroneousConversationsCount: number;
}

export interface RequestStatistics extends Record<string, unknown> {
  /** Number of transactions for the request. */
  transactionsCount: number;
}

export interface ConversationalTask extends AnalyzeConversationTaskBase {
  /** The input ConversationItem and its optional parameters */
  analysisInput: ConversationAnalysisOptions;
  /** Input parameters necessary for a Conversation task. */
  parameters: ConversationTaskParameters;
  kind: "Conversation";
}

export interface ConversationAnalysisOptions {
  /** The abstract base for a user input formatted conversation (e.g., Text, Transcript). */
  conversationItem: ConversationItemBase;
}

export interface ConversationItemBase extends Record<string, unknown> {
  /** The ID of a conversation item. */
  id: string;
  /** The participant ID of a conversation item. */
  participantId: string;
  /** The override language of a conversation item in BCP 47 language representation. */
  language?: string;
  /** Enumeration of supported conversational modalities. */
  modality?: "transcript" | "text";
  /** The role of the participant. */
  role?: "agent" | "customer" | "generic";
}

export interface ConversationTaskParameters {
  /** The name of the project to use. */
  projectName: string;
  /** The name of the deployment to use. */
  deploymentName: string;
  /** If true, the service will return more detailed information in the response. */
  verbose?: boolean;
  /** If true, the service will keep the query for further review. */
  isLoggingEnabled?: boolean;
  /** Specifies the method used to interpret string offsets.  Defaults to Text Elements (Graphemes) according to Unicode v8.0.0. For additional information see https://aka.ms/text-analytics-offsets. */
  stringIndexType?: "TextElements_v8" | "UnicodeCodePoint" | "Utf16CodeUnit";
  /** The name of a target project to forward the request to. */
  directTarget?: string;
  /** A dictionary representing the parameters for each target project. */
  targetProjectParameters?: Record<string, AnalysisParameters>;
}

export interface AnalysisParametersBase {
  /** The API version to use when call a specific target service. */
  apiVersion?: string;
  targetProjectKind:
    | "AnalysisParameters"
    | "Luis"
    | "Conversation"
    | "QuestionAnswering";
}

export interface TextConversationItem extends ConversationItemBase {
  /** The text input */
  text: string;
}

export interface LuisParameters
  extends AnalysisParametersBase,
    Record<string, unknown> {
  /** The utterance to predict. */
  query?: string;
  /** This customizes how the service calls LUIS Generally Available projects. */
  callingOptions?: LuisCallingOptions;
  targetProjectKind: "Luis";
}

export interface LuisCallingOptions {
  /** Enable verbose response. */
  verbose?: boolean;
  /** Save log to add in training utterances later. */
  log?: boolean;
  /** Set true to show all intents. */
  "show-all-intents"?: boolean;
  /** The timezone offset for the location of the request. */
  timezoneOffset?: number;
  /** Enable spell checking. */
  spellCheck?: boolean;
  /** The subscription key to use when enabling Bing spell check */
  "bing-spell-check-subscription-key"?: string;
}

export interface ConversationParameters extends AnalysisParametersBase {
  /** The option to set to call a Conversation project. */
  callingOptions?: ConversationCallingOptions;
  targetProjectKind: "Conversation";
}

export interface ConversationCallingOptions {
  /** The language of the query in BCP 47 language representation.. */
  language?: string;
  /** If true, the service will return more detailed information. */
  verbose?: boolean;
  /** If true, the query will be saved for customers to further review in authoring, to improve the model quality. */
  isLoggingEnabled?: boolean;
}

export interface QuestionAnsweringParameters extends AnalysisParametersBase {
  /** The options sent to a Question Answering KB. */
  callingOptions?: AnswersOptions;
  targetProjectKind: "QuestionAnswering";
}

export interface AnswersOptions {
  /** Exact QnA ID to fetch from the knowledge base, this field takes priority over question. */
  qnaId?: number;
  /** User question to query against the knowledge base. */
  question?: string;
  /** Max number of answers to be returned for the question. */
  top?: number;
  /** Unique identifier for the user. */
  userId?: string;
  /** Minimum threshold score for answers, value ranges from 0 to 1. */
  confidenceScoreThreshold?: number;
  /** Context object with previous QnA's information. */
  context?: KnowledgeBaseAnswerContext;
  /** Type of ranker to be used. */
  rankerType?: "QuestionOnly" | "Default";
  /** Filter QnAs based on given metadata list and knowledge base sources. */
  filters?: QueryFilters;
  /** To configure Answer span prediction feature. */
  answerSpanRequest?: ShortAnswerOptions;
  /** (Optional) Flag to enable Query over Unstructured Sources. */
  includeUnstructuredSources?: boolean;
}

export interface KnowledgeBaseAnswerContext {
  /** Previous turn top answer result QnA ID. */
  previousQnaId: number;
  /** Previous user query. */
  previousUserQuery?: string;
}

export interface QueryFilters {
  /** Find QnAs that are associated with the given list of metadata. */
  metadataFilter?: MetadataFilter;
  /** Find QnAs that are associated with any of the given list of sources in knowledge base. */
  sourceFilter?: Array<string>;
  /** Logical operation used to join metadata filter with source filter. */
  logicalOperation?: "AND" | "OR";
}

export interface MetadataFilter {
  metadata?: Array<MetadataRecord>;
  /** Operation used to join metadata filters. */
  logicalOperation?: "AND" | "OR";
}

export interface MetadataRecord {
  /** Metadata Key from Metadata dictionary used in the QnA. */
  key: string;
  /** Metadata Value from Metadata dictionary used in the QnA. */
  value: string;
}

export interface ShortAnswerOptions {
  /** Enable or disable Answer Span prediction. */
  enable: true;
  /** Minimum threshold score required to include an answer span, value ranges from 0 to 1. */
  confidenceScoreThreshold?: number;
  /** Number of Top answers to be considered for span prediction from 1 to 10. */
  topAnswersWithSpan?: number;
}

export interface AnalyzeConversationPIITask
  extends AnalyzeConversationLROTaskBase {
  /** Supported parameters for a Conversational PII detection and redaction task. */
  parameters?: ConversationPIITaskParameters;
  kind: "ConversationalPIITask";
}

export interface ConversationPIITaskParameters extends PreBuiltTaskParameters {
  /** Describes the PII categories to return for detection. If not provided, 'default' categories will be returned which will vary with the language. */
  piiCategories?: Array<
    | "Address"
    | "CreditCard"
    | "Email"
    | "Name"
    | "NumericIdentifier"
    | "PhoneNumber"
    | "All"
    | "Default"
  >;
  /** Flag to indicate if audio redaction is requested. By default audio redaction will not be performed. */
  includeAudioRedaction?: boolean;
  /** For transcript conversations, this parameter provides information regarding which content type (ITN, Text, Lexical, Masked ITN) should be used for entity detection. The details of the entities detected - like the offset, length and the text itself - will correspond to the text type selected here. */
  redactionSource?: "lexical" | "itn" | "maskedItn" | "text";
}

export interface PreBuiltTaskParameters extends TaskParameters {
  modelVersion?: string;
}

export interface TaskParameters {
  loggingOptOut?: boolean;
}

export interface ConversationPIIItemResult {
  id: string;
  /** The transcript content response generated by the service with all necessary personally identifiable information redacted. */
  redactedContent: RedactedTranscriptContent;
  entities: Array<Entity>;
}

export interface RedactedTranscriptContent {
  /** The redacted output for inverse text normalized format input. */
  itn?: string;
  /** The redacted output for masked inverse text normalized format input. */
  maskedItn?: string;
  /** The redacted output for text (Microsoft's Speech to Text 'display') format input. */
  text?: string;
  /** The redacted output for lexical format input. */
  lexical?: string;
  /** The list of redacted audio segments. */
  audioTimings?: Array<AudioTiming>;
}

export interface AudioTiming {
  /** Offset from start of speech audio, in ticks. 1 tick = 100 ns. */
  offset?: number;
  /** Duration of word articulation, in ticks. 1 tick = 100 ns. */
  duration?: number;
}

export interface Entity {
  /** Entity text as appears in the request. */
  text: string;
  /** Entity type. */
  category: string;
  /** (Optional) Entity sub type. */
  subcategory?: string;
  /** Start position for the entity text. Use of different 'stringIndexType' values can affect the offset returned. */
  offset: number;
  /** Length for the entity text. Use of different 'stringIndexType' values can affect the length returned. */
  length: number;
  /** Confidence score between 0 and 1 of the extracted entity. */
  confidenceScore: number;
}

export interface TextConversation extends ConversationBase {
  /** Ordered list of text conversation items in the conversation. */
  conversationItems: Array<TextConversationItem>;
  modality: "text";
}

export interface TranscriptConversation extends ConversationBase {
  /** Ordered list of transcript conversation items in the conversation. */
  conversationItems: Array<TranscriptConversationItem>;
  modality: "transcript";
}

export interface TranscriptConversationItem extends ConversationItemBase {
  /** Inverse Text Normalization representation of input. The inverse-text-normalized form is the recognized text from Microsoft’s Speech to Text API, with phone numbers, numbers, abbreviations, and other transformations applied. */
  itn?: string;
  /** The Inverse Text Normalized format with profanity masking applied. */
  maskedItn?: string;
  /** The display form of the recognized text from speech to text API, with punctuation and capitalization added. */
  text?: string;
  /** The lexical form of the recognized text from speech to text API with the actual words recognized. */
  lexical?: string;
  /** The list of word level audio timing information */
  audioTimings?: Array<WordLevelTiming>;
}

export interface WordLevelTiming extends AudioTiming {
  /** The word recognized. */
  word?: string;
}

export interface AnalyzeConversationPIIResult
  extends AnalyzeConversationJobResultBase {
  /** The result from PII detection and redaction operation for each conversation. */
  results: ConversationPIIResults;
  kind: "ConversationalPIIResults";
}

export interface ConversationPIIResults extends PreBuiltResult {
  conversations: Array<ConversationPIIResultsConversationsItem>;
}

export interface ConversationPIIResultsConversationsItem
  extends ConversationPIIResult,
    ConversationResultBase {}

export interface ConversationPIIResult {
  /** Enumeration of PII detection and redaction operation results for all the conversation items in a conversation. */
  conversationItems: Array<ConversationPIIItemResult>;
}

export interface ConversationResultBase {
  /** Unique, non-empty conversation identifier. */
  id: string;
  /** Warnings encountered while processing document. */
  warnings: Array<InputWarning>;
  /** If showStats=true was specified in the request this field will contain information about the conversation payload. */
  statistics?: ConversationStatistics;
}

export interface InputWarning {
  /** Warning code. */
  code: string;
  /** Warning message. */
  message: string;
  /** A JSON pointer reference indicating the target object. */
  targetRef?: string;
}

export interface ConversationStatistics {
  /** Number of text units for the request. */
  transactionsCount: number;
}

export interface PreBuiltResult {
  /** Errors by document id. */
  errors: Array<InputError>;
  /** if showStats=true was specified in the request this field will contain information about the request payload. */
  statistics?: RequestStatistics;
  /** This field indicates which model is used for scoring. */
  modelVersion: string;
}

export interface InputError {
  /** The ID of the input. */
  id: string;
  /** Error encountered. */
  error: ErrorModel;
}

export interface AnalyzeConversationSummarizationTask
  extends AnalyzeConversationLROTaskBase {
  /** Supported parameters for an conversational summarization task. */
  parameters?: ConversationSummarizationTaskParameters;
  kind: "ConversationalSummarizationTask";
}

export interface ConversationSummarizationTaskParameters
  extends PreBuiltTaskParameters {
  summaryAspects: Array<"issue" | "resolution">;
}

export interface AnalyzeConversationSummarizationResult
  extends AnalyzeConversationJobResultBase {
  results: SummaryResult;
  kind: "ConversationalSummarizationResults";
}

export interface SummaryResult extends PreBuiltResult {
  conversations: Array<SummaryResultConversationsItem>;
}

export interface SummaryResultConversationsItem
  extends ConversationsSummaryResult,
    ConversationResultBase {}

export interface ConversationsSummaryResult {
  summaries: Array<ConversationsSummaryResultSummariesItem>;
}

export interface ConversationsSummaryResultSummariesItem
  extends SummaryResultItem {}

export interface SummaryResultItem {
  aspect: string;
  text: string;
}

export type AnalyzeConversationTask = ConversationalTask;
export type Conversation = TextConversation | TranscriptConversation;
export type AnalyzeConversationLROTask =
  | AnalyzeConversationPIITask
  | AnalyzeConversationSummarizationTask;
export type AnalyzeConversationJobResult =
  | AnalyzeConversationPIIResult
  | AnalyzeConversationSummarizationResult;
export type AnalysisParameters =
  | LuisParameters
  | ConversationParameters
  | QuestionAnsweringParameters;
